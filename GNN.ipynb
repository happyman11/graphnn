{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3400722/2944165975.py:24: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "from natsort import natsorted\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Dict, List, Optional\n",
    "\n",
    "import albumentations as AB \n",
    "from PIL import Image\n",
    "import skimage.io\n",
    "import skimage.measure\n",
    "import skimage.segmentation\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "## Imports for plotting\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "sns.set()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgb\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "\n",
    "\n",
    "\n",
    "## Progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "# PyTorch Lightning\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
    "    ! pip install --quiet pytorch-lightning>=1.4\n",
    "    import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, MLFlowLogger\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# # Torch geometric\n",
    "# import torch_geometric.data\n",
    "# import torch_geometric.utils \n",
    "# torch geometric\n",
    "try:\n",
    "    import torch_geometric\n",
    "except ModuleNotFoundError:\n",
    "    # Installing torch geometric packages with specific CUDA+PyTorch version.\n",
    "    # See https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html for details\n",
    "    TORCH = torch.__version__.split('+')[0]\n",
    "    CUDA = 'cu' + torch.version.cuda.replace('.','')\n",
    "\n",
    "    ! pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "    ! pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "    ! pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "    ! pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "    ! pip install torch-geometric\n",
    "    import torch_geometric\n",
    "import torch_geometric.nn as geom_nn\n",
    "import torch_geometric.data as geom_data\n",
    "import torch_geometric.loader as geom_loader\n",
    "import torch_geometric.transforms as geom_transforms\n",
    "import torch_geometric.utils as geom_utils\n",
    "# from torch_geometric.nn import GraphUNet\n",
    "# from torch_geometric.utils import dropout_adj\n",
    "\n",
    "from monai.data import CacheDataset, list_data_collate\n",
    "from monai.config import print_config\n",
    "from monai.losses import DiceLoss\n",
    "\n",
    "from monai.utils import set_determinism\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged, AddChanneld, Resized, ScaleIntensityd, Flipd, Rotate90d,\n",
    "    RandAdjustContrastd, RandHistogramShiftd, RandGaussianNoised, RandGaussianSmoothd, RandGaussianSharpend, \n",
    "    RandAffined, RandRotate90d, RandFlipd, RandZoomd, RandSpatialCropd, RandCropByPosNegLabeld, \n",
    "    ToTensord\n",
    ")\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.determinstic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images and 3000 labels.\n",
      "Found 20 images and 20 labels.\n",
      "Found 20 images and 20 labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type     | Params\n",
      "-------------------------------------------\n",
      "0 | model         | GNNModel | 63.7 K\n",
      "1 | loss_function | DiceLoss | 0     \n",
      "-------------------------------------------\n",
      "63.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "63.7 K    Total params\n",
      "0.255     Total estimated model params size (MB)\n",
      "Checkpoint directory /home/qtran/graph/logs exists and is not empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: 100%|██████████| 604/604 [21:24<00:00,  2.13s/it, loss=0.518, v_num=0, val_loss=0.492]\n"
     ]
    }
   ],
   "source": [
    "class PairedDataModule(LightningDataModule):\n",
    "    def __init__(self, \n",
    "        train_image_dirs: List[str]=['/data/train/images'],\n",
    "        train_label_dirs: List[str]=['/data/train/labels'], \n",
    "        val_image_dirs: List[str]=['/data/val/images'], \n",
    "        val_label_dirs: List[str]=['/data/val/labels'],\n",
    "        test_image_dirs: List[str]=['/data/test/images'],\n",
    "        test_label_dirs: List[str]=['/data/test/labels'],\n",
    "    ):\n",
    "        \"\"\"[summary]\n",
    "\n",
    "        Args:\n",
    "            batch_size (int, optional): [description]. Defaults to 32.\n",
    "            train_image_dirs (List[str], optional): [description]. Defaults to ['/data/train/images'].\n",
    "            train_label_dirs (List[str], optional): [description]. Defaults to ['/data/train/labels'].\n",
    "            val_image_dirs (List[str], optional): [description]. Defaults to ['/data/val/images'].\n",
    "            val_label_dirs (List[str], optional): [description]. Defaults to ['/data/val/labels'].\n",
    "            test_image_dirs (List[str], optional): [description]. Defaults to ['/data/test/images'].\n",
    "            test_label_dirs (List[str], optional): [description]. Defaults to ['/data/test/labels'].\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.train_image_dirs = train_image_dirs\n",
    "        self.train_label_dirs = train_label_dirs\n",
    "        self.val_image_dirs = val_image_dirs\n",
    "        self.val_label_dirs = val_label_dirs\n",
    "        self.test_image_dirs = test_image_dirs\n",
    "        self.test_label_dirs = test_label_dirs\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download, split, etc...\n",
    "        # only called on 1 GPU/TPU in distributed\n",
    "        pass\n",
    "    \n",
    "    def glob_dict(\n",
    "        self, \n",
    "        image_dirs: List[str], \n",
    "        label_dirs: List[str],\n",
    "        ext: str='*.png',\n",
    "    ) -> Dict[str, List[str]]:\n",
    "        assert image_dirs is not None and label_dirs is not None\n",
    "        assert len(image_dirs) == len(label_dirs)\n",
    "        # Glob all image files in image_dirs\n",
    "        image_paths = [Path(folder).rglob(ext) for folder in image_dirs]\n",
    "        image_files = natsorted([str(path) for path_list in image_paths for path in path_list])\n",
    "\n",
    "        # Glob all label files in label_dirs\n",
    "        label_paths = [Path(folder).rglob(ext) for folder in label_dirs]\n",
    "        label_files = natsorted([str(path) for path_list in label_paths for path in path_list])\n",
    "\n",
    "        # Check that the number of image and label files match\n",
    "        print(f'Found {len(image_files)} images and {len(label_files)} labels.')\n",
    "        assert len(image_files) == len(label_files)\n",
    "\n",
    "        # Create a dictionary of image and label files\n",
    "        data_dicts = [\n",
    "            {\"image\": image_file,  \n",
    "             \"label\": label_file} for image_file, label_file in zip(image_files, label_files)\n",
    "        ]\n",
    "        return data_dicts\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # make assignments here (val/train/test split)\n",
    "        # called on every process in DDP\n",
    "        self.train_data_dicts = self.glob_dict(self.train_image_dirs, self.train_label_dirs, ext='*.png')\n",
    "        self.val_data_dicts = self.glob_dict(self.val_image_dirs, self.val_label_dirs, ext='*.png')\n",
    "        self.test_data_dicts = self.glob_dict(self.test_image_dirs, self.test_label_dirs, ext='*.png')\n",
    "        # set_determinism(seed=0)\n",
    "\n",
    "class ImageGrid(object):\n",
    "    def __init__(self, array=None, diff_edge=False, seed=32):\n",
    "        \"\"\"[summary]\n",
    "\n",
    "        Args:\n",
    "            array ([numpy array], optional): [H W C=1,3 tensor]. Defaults to None.\n",
    "            diff_edge (bool, optional): [description]. Defaults to False.\n",
    "        \"\"\"\n",
    "        self.reset()\n",
    "        # self.set_array(array, diff_edge=diff_edge)\n",
    "        self.array = array.astype(np.float32) if array.ndim == 3 else np.expand_dims(array, axis=2)\n",
    "        self.height, self.width = array.shape[:2]\n",
    "        self.seed = seed\n",
    "        # Create the graph\n",
    "        self.graph = nx.grid_2d_graph(self.height, self.width)\n",
    "        \n",
    "        self.set_nodes(weight=None)\n",
    "        self.set_edges(weight=None, diff_edge=diff_edge)\n",
    "        # for n, node in enumerate(self.graph.nodes):\n",
    "        #     print(self.graph.nodes[node])\n",
    "        self.number_of_nodes = self.graph.number_of_nodes()\n",
    "        self.number_of_edges = self.graph.number_of_edges()\n",
    "\n",
    "    def reset(self):\n",
    "        self.height = 0\n",
    "        self.width = 0\n",
    "        self.array = None\n",
    "        self.graph = None\n",
    "\n",
    "    def set_edges(self, weight=None, diff_edge=True, cc=8):\n",
    "        # for e, edge in enumerate(self.graph.edges):\n",
    "        #     self.graph.edges[edge]['weight'] = 0.5\n",
    "\n",
    "        if cc==8:\n",
    "            k=1\n",
    "            self.graph.add_edges_from([\n",
    "                ((x+0, y+0), (x+0, y+k))\n",
    "                for x in range(self.width-k)\n",
    "                for y in range(self.height-k)\n",
    "            ] + [\n",
    "                ((x+0, y+0), (x+k, y+0))\n",
    "                for x in range(self.width-k)\n",
    "                for y in range(self.height-k)\n",
    "            ] + [\n",
    "                ((x+k, y+0), (x+k, y+k))\n",
    "                for x in range(self.width-k)\n",
    "                for y in range(self.height-k)\n",
    "            ] + [\n",
    "                ((x+0, y+k), (x+k, y+k))\n",
    "                for x in range(self.width-k)\n",
    "                for y in range(self.height-k)\n",
    "            ], weight=0.5)\n",
    "\n",
    "            # diagonal edges\n",
    "            self.graph.add_edges_from([\n",
    "                ((x+0, y+0), (x+k, y+k))\n",
    "                for x in range(self.width-k)\n",
    "                for y in range(self.height-k)\n",
    "            ] + [\n",
    "                ((x+k, y+0), (x+0, y+k))\n",
    "                for x in range(self.width-k)\n",
    "                for y in range(self.height-k)\n",
    "            ], weight=0.5)\n",
    "            \n",
    "            np.random.seed(self.seed)\n",
    "            # k = np.random.choice([2, 4, 8, 16])\n",
    "            # straight edges\n",
    "            x = np.random.choice(self.width, size=(self.height*self.width//4), replace=True)\n",
    "            y = np.random.choice(self.height,  size=(self.height*self.width//4), replace=True)\n",
    "            u = np.random.choice(self.width, size=(self.height*self.width//4), replace=True)\n",
    "            v = np.random.choice(self.height,  size=(self.height*self.width//4), replace=True)\n",
    "            self.graph.add_edges_from([\n",
    "                ((x, y), (u, v)) for x, y, u, v in zip(x, y, u, v)\n",
    "            ], weight=0.5)\n",
    "\n",
    "            # # diagonal edges\n",
    "            # self.graph.add_edges_from([\n",
    "            #     ((x+0, y+0), (x+k, y+k))\n",
    "            #     for x in range(self.width-k)\n",
    "            #     for y in range(self.height-k)\n",
    "            # ] + [\n",
    "            #     ((x+k, y+0), (x+0, y+k))\n",
    "            #     for x in range(self.width-k)\n",
    "            #     for y in range(self.height-k)\n",
    "            # ], weight=0.5)\n",
    "            \n",
    "        elif cc==4: \n",
    "            # connected component is equal to 4 already in the grid\n",
    "            pass\n",
    "\n",
    "        # Add edge to master node \n",
    "        self.graph.add_edges_from([\n",
    "            ((x, y), (-1, 0))\n",
    "            for x in range(self.width)\n",
    "            for y in range(self.height)\n",
    "        ], weight=0.5)\n",
    "\n",
    "        self.graph.add_edges_from([\n",
    "            ((x, y), (0, -1))\n",
    "            for x in range(self.width)\n",
    "            for y in range(self.height)\n",
    "        ], weight=0.5)\n",
    "\n",
    "\n",
    "        if diff_edge==\"mean\":\n",
    "            for e, edge in enumerate(self.graph.edges):\n",
    "                # Compute the mean of the affinity\n",
    "                self.graph.edges[edge]['weight'] = (self.array[edge[0]] - self.array[edge[1]]) * 0.5\n",
    "        elif diff_edge==\"diff\":\n",
    "            for e, edge in enumerate(self.graph.edges):\n",
    "                # Compute the affinity, 1 - difference\n",
    "                self.graph.edges[edge]['weight'] = ( 1 - np.abs(self.array[edge[0]] - self.array[edge[1]]) )\n",
    "                # if self.array[edge[0]] == self.array[edge[1]] == 0: # We dont care the connection of background\n",
    "                #     self.graph.edges[edge]['weight'] = np.abs(self.array[edge[0]] - self.array[edge[1]]) # 0\n",
    "                # else:\n",
    "                #     self.graph.edges[edge]['weight'] = ( 1 - np.abs(self.array[edge[0]] - self.array[edge[1]]) )\n",
    "\n",
    "    def set_nodes(self, weight=None):\n",
    "        for n, node in enumerate(self.graph.nodes):\n",
    "            y = n // self.width\n",
    "            x = n % self.width\n",
    "            self.graph.nodes[node]['weight'] = self.array[y,x,:] \\\n",
    "                if weight is None else np.array([weight], dtype=np.float32)\n",
    "        # Set master node \n",
    "        self.graph.add_node((-1, 0), weight=np.array([1.0], dtype=np.float32) if weight is None else np.array([weight], dtype=np.float32)) \n",
    "        self.graph.add_node((0, -1), weight=np.array([0.0], dtype=np.float32) if weight is None else np.array([weight], dtype=np.float32)) \n",
    "\n",
    "\n",
    "class GraphBasedDataset(Dataset):\n",
    "    def __init__(self, data_dicts, transforms=None):\n",
    "        self.data_dicts = data_dicts\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # If use AB\n",
    "        image_file = self.data_dicts[index]['image']\n",
    "        label_file = self.data_dicts[index]['label']\n",
    "        image_array = skimage.io.imread(image_file).astype(np.uint8) \n",
    "        label_array = skimage.io.imread(label_file).astype(np.uint8) \n",
    "\n",
    "        if self.transforms:\n",
    "            transformed = self.transforms(image=image_array, mask=label_array)\n",
    "            image = transformed['image'].astype(np.float32) / 255.0\n",
    "            label = transformed['mask'].astype(np.float32) / 255.0\n",
    "        else:\n",
    "            image = image_array.astype(np.float32) / 255.0\n",
    "            label = label_array.astype(np.float32) / 255.0\n",
    "        \n",
    "        # If use Monai\n",
    "        # data_dict = self.data_dicts[index]\n",
    "        # if self.transforms:\n",
    "        #     # print(data_dict)\n",
    "        #     data_dict = self.transforms(data_dict)\n",
    "        #     image = data_dict['image'].squeeze()\n",
    "        #     label = data_dict['label'].squeeze()\n",
    "        #     # print(image.shape, label.shape)\n",
    "        # else:\n",
    "        #     image, label = data_dict[\"image\"], data_dict[\"label\"]\n",
    "        seed = index\n",
    "        image_grid = ImageGrid(image, diff_edge=\"diff\", seed=seed)\n",
    "        label_grid = ImageGrid(label, diff_edge=\"diff\", seed=seed)\n",
    "\n",
    "        image_graph = torch_geometric.utils.from_networkx(image_grid.graph, \n",
    "                                                          group_node_attrs=['weight'],\n",
    "                                                          group_edge_attrs=['weight'])\n",
    "        label_graph = torch_geometric.utils.from_networkx(label_grid.graph, \n",
    "                                                          group_node_attrs=['weight'],\n",
    "                                                          group_edge_attrs=['weight'])\n",
    "        # Normalize coordinate\n",
    "        # image_graph.x = geom_transforms.NormalizeScale()(image_graph.x)\n",
    "        # label_graph.x = geom_transforms.NormalizeScale()(label_graph.x)\n",
    "        \n",
    "        # if self.transforms:\n",
    "        #     pass\n",
    "        # print(image_graph.x.shape, image_graph.edge_index.shape, image_graph.edge_attr.shape)\n",
    "        # print(label_graph.x.shape, label_graph.edge_index.shape, label_graph.edge_attr.shape)\n",
    "        # return (image_graph.x, image_graph.edge_index), (label_graph.x, label_graph.edge_index)\n",
    "        return {\"image\": image_graph, \"label\": label_graph}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_dicts)\n",
    "\n",
    "class GraphBasedDataModule(PairedDataModule):\n",
    "    def __init__(self, \n",
    "        batch_size: int=32,\n",
    "        train_image_dirs: List[str]=['/data/train/images'],\n",
    "        train_label_dirs: List[str]=['/data/train/labels'], \n",
    "        val_image_dirs: List[str]=['/data/val/images'], \n",
    "        val_label_dirs: List[str]=['/data/val/labels'],\n",
    "        test_image_dirs: List[str]=['/data/test/images'],\n",
    "        test_label_dirs: List[str]=['/data/test/labels'],\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.train_image_dirs = train_image_dirs\n",
    "        self.train_label_dirs = train_label_dirs\n",
    "        self.val_image_dirs = val_image_dirs\n",
    "        self.val_label_dirs = val_label_dirs\n",
    "        self.test_image_dirs = test_image_dirs\n",
    "        self.test_label_dirs = test_label_dirs\n",
    "\n",
    "    def _shared_dataloader(self, data_dicts, transforms=None, shuffle=True, drop_last=False, num_workers=8):\n",
    "        dataset = GraphBasedDataset(data_dicts, transforms=transforms)\n",
    "        dataloader = geom_loader.DataLoader(\n",
    "            dataset=dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            num_workers=num_workers, \n",
    "            # collate_fn=list_data_collate,\n",
    "            shuffle=shuffle,\n",
    "        )\n",
    "        return dataloader\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_transforms = AB.Compose([\n",
    "            AB.OneOf([\n",
    "                AB.RandomSizedCrop(min_max_height=(160, 250), height=256, width=256, p=0.5),\n",
    "                # AB.PadIfNeeded(min_height=256, min_width=256, p=0.5)\n",
    "            ], p=1),    \n",
    "            AB.VerticalFlip(p=0.5),              \n",
    "            AB.RandomRotate90(p=0.5),\n",
    "            # AB.OneOf([\n",
    "            #     AB.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03, p=0.5),\n",
    "            #     AB.GridDistortion(p=0.5),\n",
    "            #     AB.OpticalDistortion(distort_limit=2, shift_limit=0.5, p=1)                  \n",
    "            #     ], p=0.8),\n",
    "            AB.CLAHE(p=0.8),\n",
    "            AB.RandomBrightnessContrast(p=0.8),    \n",
    "            AB.RandomGamma(p=0.8), \n",
    "            AB.ToFloat(max_value=1.0, p=1.0),\n",
    "            AB.Resize(height=128, width=128, p=1),\n",
    "        ])\n",
    "        return self._shared_dataloader(self.train_data_dicts, \n",
    "            transforms=train_transforms, \n",
    "            shuffle=True,\n",
    "            drop_last=False,\n",
    "            num_workers=12\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        val_transforms = AB.Compose([\n",
    "            AB.ToFloat(max_value=1.0, p=1.0),\n",
    "            AB.Resize(height=128, width=128, p=1),\n",
    "        ])\n",
    "        return self._shared_dataloader(self.val_data_dicts, \n",
    "            transforms=val_transforms, \n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "            num_workers=4\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        test_transforms = AB.Compose([\n",
    "            AB.ToFloat(max_value=1.0, p=1.0),\n",
    "            AB.Resize(height=128, width=128, p=1),\n",
    "        ])\n",
    "        return self._shared_dataloader(self.test_data_dicts, \n",
    "            transforms=test_transforms, \n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "            num_workers=4\n",
    "        )\n",
    "\n",
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, c_in, c_hidden, c_out, num_layers=3, dp_rate=0.5, **kwargs):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            c_in - Dimension of input features\n",
    "            c_hidden - Dimension of hidden features\n",
    "            c_out - Dimension of the output features. Usually number of classes in classification\n",
    "            num_layers - Number of \"hidden\" graph layers\n",
    "            dp_rate - Dropout rate to apply throughout the network\n",
    "            kwargs - Additional arguments for the graph layer (e.g. number of heads for GAT)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # gnn_layer = gnn_layer_by_name[layer_name]\n",
    "        node_layer = geom_nn.GATConv\n",
    "        # node_layer = geom_nn.GATv2Conv\n",
    "        # node_layer = geom_nn.ResGatedGraphConv\n",
    "\n",
    "        node_model = []\n",
    "        in_channels, out_channels = c_in, c_hidden\n",
    "        for _ in range(num_layers-1):\n",
    "            node_model += [\n",
    "                node_layer(in_channels=in_channels,\n",
    "                          out_channels=out_channels,\n",
    "                          #dropout=dp_rate,\n",
    "                          **kwargs),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dp_rate)\n",
    "            ]\n",
    "            in_channels = c_hidden\n",
    "        node_model += [node_layer(in_channels=in_channels,\n",
    "                             out_channels=c_out,\n",
    "                             #dropout=dp_rate,\n",
    "                             **kwargs)]\n",
    "        self.node_model = nn.ModuleList(node_model)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            x - Input features per node\n",
    "            edge_index - List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
    "        \"\"\"\n",
    "        for node_layer in self.node_model:\n",
    "            # For graph layers, we need to add the \"edge_index\" tensor as additional input\n",
    "            # All PyTorch Geometric graph layer inherit the class \"MessagePassing\", hence\n",
    "            # we can simply check the class type.\n",
    "            if isinstance(node_layer, geom_nn.MessagePassing):\n",
    "                x, (edge_index, edge_attr) = node_layer(x, edge_index, edge_attr, return_attention_weights=True)\n",
    "                # edge_attr = alpha*( (1 - torch.abs(x[edge_index[0]] - x[edge_index[1]])) )\n",
    "            else:\n",
    "                x = node_layer(x)\n",
    "        return x, edge_attr\n",
    "\n",
    "class GridGNN(pl.LightningModule):\n",
    "    def __init__(self, **model_kwargs):\n",
    "        super().__init__()\n",
    "        # Saving hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = GNNModel(**model_kwargs)\n",
    "        self.loss_function = DiceLoss(to_onehot_y=False, \n",
    "                                      sigmoid=False, \n",
    "                                      squared_pred=False)\n",
    "\n",
    "    def forward(self, data, mode=\"train\"):\n",
    "        output, edge_attr = self.model(data.x, data.edge_index, data.edge_attr)\n",
    "        return torch.sigmoid(output), torch.sigmoid(edge_attr)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=0.0001)\n",
    "        return optimizer\n",
    "\n",
    "    def _shared_step(self, batch, batch_idx, stage: Optional[str]='_shared'):\n",
    "        images, labels = batch[\"image\"], batch[\"label\"]\n",
    "        output, attrs = self.forward(images)\n",
    "        loss = 0.5*(self.loss_function(output, labels.x) \\\n",
    "                  + self.loss_function(attrs, labels.edge_attr))\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def training_step(self, batch, batch_idx, stage: Optional[str]='train'):\n",
    "        images, labels = batch[\"image\"], batch[\"label\"]\n",
    "        output, attrs = self.forward(images)\n",
    "        loss = 0.5*(self.loss_function(output, labels.x) \\\n",
    "                  + self.loss_function(attrs, labels.edge_attr))\n",
    "        if batch_idx==0:\n",
    "            viz = torch.cat([images.x[:16384].reshape([128, 128]), \n",
    "                             labels.x[:16384].reshape([128, 128]), \n",
    "                             output[:16384].reshape([128, 128]), \n",
    "                            ], dim=-1)#[:8]\n",
    "            grid = torchvision.utils.make_grid(viz, nrow=5, padding=0)\n",
    "            tensorboard = self.logger[0].experiment\n",
    "            tensorboard.add_image(f'{stage}_samples', grid, self.current_epoch)\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._shared_step(batch, batch_idx, stage='val')\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self._shared_step(batch, batch_idx, stage='test')\n",
    "    \n",
    "    def _shared_epoch_end(self, outputs, stage: Optional[str]='_shared'):\n",
    "        loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        self.log(f'{stage}_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        return self._shared_epoch_end(outputs, stage='val')\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        return self._shared_epoch_end(outputs, stage='test')\n",
    "\n",
    "\n",
    "log_dir = \"logs\"\n",
    "tsb_logger = TensorBoardLogger(save_dir=os.path.join(log_dir, 'tsb'))\n",
    "batch_size=5\n",
    "lr=1e-4\n",
    "max_epochs=201\n",
    "\n",
    "datamodule = GraphBasedDataModule(\n",
    "    batch_size=batch_size,\n",
    "    train_image_dirs=['data/train/images/',],\n",
    "    train_label_dirs=['data/train/labels/',],\n",
    "    val_image_dirs=['data/test/images/',],\n",
    "    val_label_dirs=['data/test/labels/',],\n",
    "    test_image_dirs=['data/test/images/',],\n",
    "    test_label_dirs=['data/test/labels/',],\n",
    ")\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup()\n",
    "\n",
    "model = GridGNN(c_in=1, c_hidden=100, c_out=1, num_layers=8, edge_dim=1, add_self_loops=False, dp_rate=0.5)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath=log_dir,\n",
    "    filename='{epoch:02d}-{val_loss:.2f}',\n",
    "    save_top_k=3,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    gpus=-1,\n",
    "    # tpu_cores=8,\n",
    "    max_epochs=max_epochs,\n",
    "    logger=[tsb_logger],\n",
    "    callbacks=[checkpoint_callback],\n",
    "    num_sanity_val_steps=1,\n",
    "    # profiler=\"advanced\",\n",
    ")\n",
    "\n",
    "trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97ff627dab885bbe43d204bc87e8239667e521902fa2805fe1182d02706706c2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('graph': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
